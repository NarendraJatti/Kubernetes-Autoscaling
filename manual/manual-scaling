Manual HPA
=========


kubectl scale deployment flask-web-app --replicas=3

Who Handles Load Balancing?
Service (NodePort): If you're directly accessing the NodePort, the Kubernetes service itself will handle load balancing between the pods.

Ingress (NGINX): When you use the Ingress, the NGINX Ingress controller receives traffic and forwards it to the Service, which then handles distributing the traffic to the pods.
However, the Ingress controller can perform some optimizations, such as caching, rate-limiting, SSL termination, etc., but the load balancing across pods is still handled by the underlying Kubernetes Service (flask-web-app-service).

When you scale a deployment to a higher number of replicas than the cluster can support due to resource constraints, Kubernetes will create as many replicas as possible within the available resources. The remaining replicas will be in a pending state until sufficient resources are freed up or added to the cluster. This behavior allows Kubernetes to manage resources dynamically while maintaining the desired state as closely as possible

The kubectl scale command can be used to scale both deployments and statefulsets. When scaling a statefulset, Kubernetes ensures that the state and order of the pods are maintained, unlike in deployments where pods can be created and destroyed in any order.